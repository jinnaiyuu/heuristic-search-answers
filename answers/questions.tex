
\section{練習問題 2}

\begin{enumerate}
  \item グリッド経路探索問題において四方向 (上下左右) に加えて斜めにも移動できるグリッド経路探索問題を考えましょう。このとき、何を状態とするべきでしょうか。また、何を行動とするべきでしょうか。また、その場合のPythonの実装を考えてみましょう。

  \item TSPの最適解を$c^*$とします。$c_l \leq c^* \leq c_h$となるような$c_l, c_h$を発見して$c^*$の値を見積もりたいとします。どうすれば適切な$c_l, c_h$を見つけられるでしょうか。

  \item 障害物のない$3 \times 3$のグリッド上を四方向 (上下左右) に移動出来るグリッド経路探索問題を考えましょう。このとき、各状態の分枝度はいくつでしょうか。また、それらの平均の分枝度はいくつでしょうか。

  \item (難問) $3 \times 3$のスライディングタイル問題における分枝度はいくつかを正確に計算することはできるでしょうか。
  (ヒント: 各状態の分枝度はブランクの位置によって一意に決まります。状態空間上でブランクが各位置にある状態の数はいくつでしょうか？)
  
\end{enumerate}


\section{練習問題 3}

\begin{enumerate}
	\item 重複検出を使わない幅優先探索 (木探索) を実装し、$10 \times 10$程度のグリッド経路探索問題を解いてみましょう。

	\item 重複検出を使った幅優先探索を実装し、$10 \times 10$程度のグリッド経路探索問題を解いてみましょう。重複検出を使わない幅優先探索と比べて展開したノードの数はどのくらいになったでしょうか。重複検出によって枝刈りされたノードの数はどのくらいでしょうか。
	
	\item 重複検出を使った深さ優先探索を実装し、$10 \times 10$程度のグリッド経路探索問題を解いてみましょう。見つかった解は1, 2で見つけた解と比べてどのような特徴があったでしょうか。
	
	\item 重複検出を使った幅優先探索で巡回セールスマン問題を解いてみましょう。この時、見つかった解は最適解でしょうか。
	
	\item ダイクストラ法を実装し、巡回セールスマン問題を解いてみましょう。この時、見つかった解は最適解でしょうか。
	
	\item 幅優先探索も再帰によって実装することができます。再帰による深さ優先探索アルゴリズムの実装を参考にして、再帰による幅優先探索を実装してみましょう。再帰による深さ優先探索と比べてどのような違いがあるでしょうか？
\end{enumerate}


\section{練習問題 4}

\begin{enumerate}
  \item グリッド経路探索問題においてマンハッタン距離ヒューリスティックを実装し、A*探索を実装してみましょう。幅優先探索と比較して展開するノードの数は変化したでしょうか。

  \item グリッド経路探索問題において、グリッドが斜めを含めた隣り合う8マスに動ける場合を考えましょう。このとき、現在位置とゴール位置とのマンハッタン距離は許容的なヒューリスティック関数でしょうか。
  
  \item 斜め移動ありのグリッド経路探索問題においてマンハッタン距離よりも推定値が正確でありかつ許容的なヒューリスティック関数はあるでしょうか。
  (ヒント：あります。)
  
  \item ヒューリスティック関数$h$が許容的であるとします。このとき、$h'(s) = h(s) + c$は許容的でしょうか。$c$が何を満たせば許容的でしょうか。($c$は定数とする)
  \item ヒューリスティック関数$h$が無矛盾であるとします。このとき、$h'(s) = h(s) + c$は無矛盾でしょうか。$c$が何を満たせば無矛盾でしょうか。($c$は定数とする)
  
  \item 「許容的なヒューリスティックを用いた重み付きA*探索によって発見される解は、最適解のコスト$f^*$の$w$倍以下である」ことを証明してください。
  (ヒント: 「ヒューリスティックが許容的である時、A*探索は最適解を返す」定理の証明が使えそうです。)
  
  \item \ref{sec:search-problem}節で紹介した状態空間問題のうち、強制山登り法が解を見つけることが出来ない可能性がある問題はあるでしょうか。
  (ヒント：あります。)
\end{enumerate}


\section{練習問題 5}
\begin{enumerate}
	\item $3 \times 3$のスライディングタイル問題のオープンリストにタイブレーキングを実装してみよう。$f$値が最小のノードが複数ある場合に$h$値が最小のノードを優先して展開するタイブレーキングの戦略と、逆に$h$値が最大のノードを優先する戦略を実装し、性能を比較してみよう。どちらの方が効率的だったでしょうか。それは何故でしょうか。
	
	\item グリッド経路探索問題において完全ハッシュを作ることはできるでしょうか。どのような場合に可能でしょうか。どのような場合に不可能でしょうか。

	\item $3 \times 3$のスライディングタイル問題で遅延重複検出を実装してみよう。展開時に重複検出をする場合と比較し、展開ノード数はどちらが多かったでしょうか。生成ノード数はどちらが多かったでしょうか。
\end{enumerate}


\section{練習問題 6}

\begin{enumerate}
	\item グリッド経路探索問題において、解を見つけることが目的であるとします。また、目的は解を発見することでありそのコストは重要ではないとします。このとき分枝限定法を用いることは適切でしょうか。

	\item グリッド経路探索問題において、最適解を見つけることが目的であるとします。また、非最適解は全く必要ではないとします。このとき分枝限定法を用いることは適切でしょうか。問題が巡回セールスマン問題である場合はどうでしょうか。

	\item 今、あなたはある状態空間問題を解こうとしているとします。メモリを使った通常のA*探索では深さ$d$まで探索することができ、それ以上の探索はメモリが足りずに出来ていないとします。また、問題の分枝度は$b$であるということも分かっています。このとき、外部記憶A*探索を使うことで、どのくらいの深さまで解くことができると考えられるでしょうか。ただし、外部記憶の大きさはメモリの1000倍程度であるとします。
\end{enumerate}


\section{練習問題 7}

\begin{enumerate}
    \item 〇×ゲームをMinimax法で解いてみましょう。Minimax法で解けると、あなたは〇×ゲームを弱解決したことになります。なお、〇×ゲームは盤面に対称性がある問題であり、最初の手番でプレイできる手は実質的に３種類しかないことを利用するとよいでしょう。

    \item 〇×ゲームにおいて、$\alpha$-$\beta$分枝法を使って探索を行ってみましょう。$\alpha$-$\beta$分枝法を使うことで、Minimax法と同じ結果が得られることを確認してください。また、$\alpha$-$\beta$分枝法によって探索の効率は向上したでしょうか。さらに、探索を行う行動の順序を変えると探索の効率はどのように変わるでしょうか。

    \item 〇×ゲームではルールの性質上、２つのマルを並べたら先手が有利になります。逆に２つのバツを並べられると後手が有利になります。この知識を活かして評価関数を設計してみましょう。いくつかのゲームの盤面に対して評価関数を適用し、その評価関数が直感に合致しているかを確認してみましょう。
\end{enumerate}



\section{練習問題 8}
\begin{enumerate}
	\item $4 \times 4$のグリッド経路探索問題をPDDLで記述してみましょう。それをpyperplanに入力して解いてみましょう。ある問題をPDDLで記述する方法は一つではありません。
	
	\item pyperplanで削除緩和ヒューリスティックとランドマークカットヒューリスティックとを使って、ブロックスワールドの問題を解いてみましょう。番号が若いインスタンスの方が簡単な問題になっているので、簡単な問題から試してみましょう。この時、どちらのヒューリスティックの方が効率的だったでしょうか。
	
	\item 何か解きたい問題を考えてPDDLで記述してみましょう。それをpyperplanで解いてみましょう。想定通りの正しい解が得られたでしょうか。得られなかった場合、なぜ解が得られなかったのか考えてみましょう。行動スキーマの適用条件と削除効果は正しくデザイン出来ているでしょうか。
\end{enumerate}


\section{練習問題 9}
\begin{enumerate}
	\item GPT-2はオープンソースで公開されているモデルです (\url{https://huggingface.co/openai-community/gpt2})。また、GPUがなくても、そこそこの性能のコンピュータであれば動くモデルになっています。Huggingface's Transformersを使ってGPT-2を使って文章生成をしてみましょう。生成された文章は自然な文章になっているでしょうか。
	
    \item GPT-2でビームサーチとランダムサンプリングを使っていくつか文章を生成をしてみましょう。生成された文章はどのように異なるでしょうか。
    
    \item GPT-2 XLはGPT-2のモデルサイズを大きくしたモデルです (\url{https://huggingface.co/openai-community/gpt2-xl})。GPT-2 XLでいくつか文章を生成してみましょう。生成された文章はGPT-2と比べてどのように異なるでしょうか。
    
    \item 今現在使える最新のLLMで文章を生成してみましょう。GPT-2やGPT-2 XLと比べてどのように異なるでしょうか。
\end{enumerate}
